{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df=pd.DataFrame(\n",
        "    columns = ['build_Failed', 'gh_is_pr', 'git_prev_commit_resolution_status',\n",
        "       'gh_team_size', 'gh_num_commit_comments', 'git_diff_src_churn',\n",
        "       'git_diff_test_churn', 'gh_diff_files_added', 'gh_diff_files_deleted',\n",
        "       'gh_diff_files_modified', 'gh_diff_tests_added',\n",
        "       'gh_diff_tests_deleted', 'gh_diff_src_files', 'gh_diff_doc_files',\n",
        "       'gh_diff_other_files', 'gh_sloc', 'gh_test_lines_per_kloc',\n",
        "       'gh_test_cases_per_kloc', 'gh_asserts_cases_per_kloc', 'tr_build_id',\n",
        "       'gh_build_started_at'],\n",
        "    dtype='object')\n",
        "\n",
        "path = '/mnt/d/PFE/Code/CI-Failing-Builds-Detection/dataset'\n",
        "\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        if filename[-4:]==\".csv\":\n",
        "            df = pd.concat([df, pd.read_csv(os.path.join(dirname, filename))])\n",
        "\n",
        "X = df.iloc[:,1:19]\n",
        "y = df.iloc[:,0].astype(int)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val , y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.2, shuffle=True, stratify=y, random_state=42) # keep ratio of classes in split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modifiable Decision Tree model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "class modDecisionTree:\n",
        "    \"\"\"\n",
        "    Represents the classification model\n",
        "    based on sklearn implementation with added methods for modifying single nodes\n",
        "    nodes are indexed depth first\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, max_depth=3, random_state=42):\n",
        "        # need to add init of other hyper-param\n",
        "        self.max_depth = max_depth\n",
        "        self.model = DecisionTreeClassifier(max_depth=max_depth, splitter='random', random_state=random_state)\n",
        "    \n",
        "\n",
        "    def fit(self, X_train, y_train, columns_names):\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.tree = self.model.tree_\n",
        "        self.n_nodes = self.tree.node_count       # nbr of nodes\n",
        "        self.features = self.tree.feature         # list of each node's feature\n",
        "        self.thresholds = self.tree.threshold     # list of each node's threshold\n",
        "        self.columns_names = columns_names\n",
        "        self.features_names = [list(self.columns_names)[i] for i in self.features]\n",
        "        self.nodes_type = self.get_nodes_type()  # a node is either a split node or a terminal node/leaf\n",
        "\n",
        "\n",
        "    def evaluate(self, X_val, y_val):\n",
        "        y_pred = self.model.predict(X_val)\n",
        "        metrics = {}\n",
        "        metrics['F1'] = f1_score(y_pred ,y_val)\n",
        "        return metrics\n",
        "\n",
        "\n",
        "    def feature_importance(self):\n",
        "        feat_imp = []\n",
        "        for name, importance in zip(self.features_names , self.model.feature_importances_):\n",
        "            feat_imp.append((name, importance))\n",
        "        feat_imp.sort(key=lambda t:t[1], reverse=True)\n",
        "        return feat_imp\n",
        "\n",
        "\n",
        "    def plot_tree(self):\n",
        "        plt.figure(figsize=(15,10))  # set plot size (denoted in inches)\n",
        "        tree.plot_tree(self.model, fontsize=10, class_names=['pass','fail'])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def get_nodes_type(self):\n",
        "        children_left = self.tree.children_left\n",
        "        children_right = self.tree.children_right\n",
        "        node_depth = np.zeros(shape=self.n_nodes, dtype=np.int64)\n",
        "        is_leaves = np.zeros(shape=self.n_nodes, dtype=bool)\n",
        "        stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
        "        while len(stack) > 0:\n",
        "            # 'pop' ensures each node is only visited once\n",
        "            node_id, depth = stack.pop()\n",
        "            node_depth[node_id] = depth\n",
        "            # If the left and right child of a node is not the same we have a split node\n",
        "            is_split_node = children_left[node_id] != children_right[node_id]\n",
        "            # If a split node, append left and right children and depth to `stack`\n",
        "            # so we can loop through them\n",
        "            if is_split_node:\n",
        "                stack.append((children_left[node_id], depth + 1))\n",
        "                stack.append((children_right[node_id], depth + 1))\n",
        "            else:\n",
        "                is_leaves[node_id] = True\n",
        "        return is_leaves\n",
        "\n",
        "\n",
        "    def node_is_leaf(self, node):\n",
        "        \"\"\"Returns whether a node is a leaf (terminal node) or a split node\"\"\"\n",
        "        return self.nodes_type[node]==1\n",
        "\n",
        "\n",
        "    def set_node_threshold(self, node, value):\n",
        "        if node>=self.tree.node_count:\n",
        "            print(\"Error: selected node id is not in the tree.\")\n",
        "            return\n",
        "        if self.node_is_leaf(node):\n",
        "            print(\"Error: can't change a leaf node's threshold.\")\n",
        "            return\n",
        "        self.thresholds[node] = value \n",
        "\n",
        "\n",
        "    def set_node_feature(self, node, feat_index=None, feat_name=None):\n",
        "        if node>=self.tree.node_count:\n",
        "            print(\"Error: selected node id is not in the tree.\")\n",
        "            return\n",
        "        if self.node_is_leaf(node):\n",
        "            print(\"Error: can't change a terminal node's feature.\")\n",
        "            return\n",
        "        # convert feature name to index if supplied with name\n",
        "        if feat_index==None:\n",
        "            feat_index = self.features_names.index(feat_name)\n",
        "        self.features[node] = feat_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### State Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tree_convolution(model, features, thresholds, node=0):\n",
        "    \"\"\"\n",
        "        convolution of each 3 nodes, with overlapping => child of 1 subtree is parent of the next\n",
        "        => after each conv, slit nodes' featuress and thresholdss are updated and terminal nodes are removed\n",
        "        returns new features,thresholds values as lists\n",
        "    \"\"\"\n",
        "    visited = []\n",
        "    queue = []\n",
        "    visited.append(node)\n",
        "    queue.append(node)\n",
        "    new_features = features\n",
        "    new_thresholds = thresholds\n",
        "    #replacing leaf default values -2 by 0 for conv\n",
        "    for node in range(model.n_nodes): \n",
        "        if new_features[node]==-2:\n",
        "            new_features[node]=0\n",
        "        if new_thresholds[node]==-2:\n",
        "            new_thresholds[node]=0\n",
        "    # BFS traversal\n",
        "    while queue:\n",
        "        node = queue.pop(0) \n",
        "        left_node = model.tree.children_left[node]\n",
        "        right_node = model.tree.children_right[node]\n",
        "        #print (node, left_node, right_node, end = \"\\n\")\n",
        "        if left_node not in visited:\n",
        "            visited.append(left_node)\n",
        "            queue.append(left_node)\n",
        "        if right_node not in visited:\n",
        "            visited.append(right_node)\n",
        "            queue.append(right_node)\n",
        "\n",
        "        # define kernel here\n",
        "        if features[left_node]==0 and features[right_node]==0: # both child nodes are leaves\n",
        "            new_node_features = 0\n",
        "            new_node_thresholds = 0\n",
        "        elif features[left_node]==0: # left node is leaf\n",
        "            new_node_features = (features[node]+features[right_node])/2\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[right_node])/2\n",
        "        elif features[right_node]==0: # right node is leaf\n",
        "            new_node_features = (features[node]+features[left_node])/2\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[left_node])/2\n",
        "        else:\n",
        "            new_node_features = (features[node]+features[left_node]+features[right_node])/3\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[left_node]+thresholds[right_node])/3\n",
        "        # save new values\n",
        "        new_features[node] = new_node_features # will auto convert to int \n",
        "        new_thresholds[node] = new_node_thresholds\n",
        "\n",
        "    return new_features, new_thresholds\n",
        "\n",
        "\n",
        "def flatten(features, thresholds):\n",
        "    return torch.cat((torch.FloatTensor(features), torch.FloatTensor(thresholds))).to(device)\n",
        "\n",
        "\n",
        "def generate_state(model, features, thresholds, nbr_of_conv):\n",
        "    features, thresholds = features.copy(), thresholds.copy()\n",
        "    for _ in range(nbr_of_conv):\n",
        "        new_features, new_thresholds = tree_convolution(model, features, thresholds) # model must be fitted => add condition?\n",
        "        features, thresholds = new_features, new_thresholds\n",
        "    return flatten(features, thresholds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reinforcement Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JvPXR-dglv1c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from collections import namedtuple, deque\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def hidden_init(layer):\n",
        "    fan_in = layer.weight.data.size()[0]\n",
        "    lim = 1. / np.sqrt(fan_in)\n",
        "    return (-lim, lim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UtpIy8-Wlyj5"
      },
      "outputs": [],
      "source": [
        "class ThresholdsNetwork(nn.Module):\n",
        "    \"\"\"Network that will predict the new thresholds vector given a state.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, seed, hidden_size=32):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            threshold_vector_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "            hidden_size (int): Number of nodes in hidden layers\n",
        "        \"\"\"\n",
        "        super(ThresholdsNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)     \n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, threshold_vector_size)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state), inplace=True)\n",
        "        x = F.relu(self.fc2(x), inplace=True)\n",
        "        out = self.fc3(x)\n",
        "        return out\n",
        "    \n",
        "\n",
        "    def get_thresholds_vector(self, state):\n",
        "        threshold_vector = self.forward(state)\n",
        "        return threshold_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oBuGtzpomnrn"
      },
      "outputs": [],
      "source": [
        "class AttributeNetwork(nn.Module):\n",
        "    \"\"\"Network that will select a new attribute for a tree node given the environment state and thresholds vector\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, number_of_attributes, seed, hidden_size=32):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            threshold_vector_size (int): Dimension of each threshold vector\n",
        "            seed (int): Random seed\n",
        "            hidden_size (int): Number of nodes in the network layers\n",
        "\n",
        "        \"\"\"\n",
        "        super(AttributeNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size+threshold_vector_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, number_of_attributes)\n",
        "\n",
        "\n",
        "    def forward(self, state, threshold_vector):\n",
        "        \"\"\"Build a critic (value) network that maps (state, threshold_vector) pairs -> Q-values.\"\"\"\n",
        "        x = torch.cat((state, threshold_vector), dim=-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "    def get_attribute(self, state, threshold_vector):\n",
        "        index_selected_attribute = torch.argmax(self.forward(state, threshold_vector)) # check argmax output\n",
        "        return index_selected_attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, buffer_size, batch_size, seed):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "        \"\"\"\n",
        "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "        states = torch.vstack([e.state for e in experiences if e is not None]).float().to(device)\n",
        "        actions = torch.vstack([torch.tensor(e.action) for e in experiences if e is not None]).float().to(device)\n",
        "        rewards = torch.vstack([torch.tensor(e.reward) for e in experiences if e is not None]).float().to(device)\n",
        "        next_states = torch.vstack([e.next_state for e in experiences if e is not None]).float().to(device)\n",
        "        dones = torch.vstack([torch.tensor(e.done) for e in experiences if e is not None]).float().to(device)\n",
        "        return zip(states, actions, rewards, next_states, dones)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6TAr3AwlnXEW"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, number_of_attributes, random_seed, hidden_size):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            threshold_vector_size (int): dimension of each threshold vector\n",
        "            random_seed (int): random seed\n",
        "            add rest\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.threshold_vector_size = threshold_vector_size\n",
        "        self.number_of_attributes = number_of_attributes\n",
        "        self.seed = random.seed(random_seed)\n",
        "        print(\"Using: \", device)\n",
        "\n",
        "        # actor Network \n",
        "        self.ThresholdsNetwork = ThresholdsNetwork(state_size, threshold_vector_size, random_seed, hidden_size).to(device)\n",
        "        self.optimizer_ThresholdsNetwork = optim.Adam(self.ThresholdsNetwork.parameters(), lr=LR_ACTOR)     \n",
        "        \n",
        "        # critic Network  \n",
        "        self.AttributeNetwork = AttributeNetwork(state_size, threshold_vector_size, number_of_attributes, random_seed, hidden_size).to(device)\n",
        "        self.optimizer_AttributeNetwork = optim.Adam(self.AttributeNetwork.parameters(), lr=LR_CRITIC, weight_decay=0)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
        "        \n",
        "\n",
        "    def act(self, state, eps=0.2):\n",
        "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
        "        # greedy epsilon with param eps\n",
        "        thresholds_vector = self.ThresholdsNetwork.get_thresholds_vector(state)\n",
        "\n",
        "        p = np.random.random() \n",
        "        if p<eps:\n",
        "            index_selected_attribute = random.choice(range(self.number_of_attributes))\n",
        "        else:\n",
        "            index_selected_attribute = self.AttributeNetwork.get_attribute(state, thresholds_vector)\n",
        "        action = (index_selected_attribute, thresholds_vector.squeeze(0)[index_selected_attribute])\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
        "        # Save experience / reward\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # if enough samples are available in memory\n",
        "        # sample a minibatch and learn/update networks\n",
        "        if len(self.memory) > BATCH_SIZE:\n",
        "            experiences = self.memory.sample()\n",
        "            self.learn(experiences, GAMMA)\n",
        "\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Updates the two neural networks using given batch of experience tuples.\n",
        "        Critic_loss = \n",
        "        Actor_loss = \n",
        "        where:\n",
        "            actor_target(state) -> action\n",
        "            critic_target(state, action) -> Q-value\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        Q_loss, X_loss = [], []\n",
        "        for experience in experiences: # for b in B\n",
        "            state, action, reward, next_state, done = experience\n",
        "            sb = state\n",
        "            k_act = int(action[0].item())\n",
        "            rb = reward\n",
        "            sb1 = next_state # S_{b+1}\n",
        "            Xb = self.ThresholdsNetwork.get_thresholds_vector(sb) # X_{b}\n",
        "            Xb1 = self.ThresholdsNetwork.get_thresholds_vector(sb1) # X_{b+1}\n",
        "            # get max_k(Qq)\n",
        "            Qq = []\n",
        "            for k in range(self.number_of_attributes):\n",
        "                # get Xe_{b+1}\n",
        "                Xeb1k = torch.zeros(len(Xb1))\n",
        "                Xeb1k[k] = Xb1[k] \n",
        "                qek = self.AttributeNetwork.get_attribute(sb1,Xeb1k)\n",
        "                Qq.append(qek)\n",
        "            maxQq = np.max(Qq)\n",
        "            # yb calc\n",
        "            if done: # terminal node\n",
        "                yb = rb\n",
        "            else:\n",
        "                yb = rb + gamma*maxQq\n",
        "\n",
        "            # compute losses for single transitions\n",
        "            # Q loss\n",
        "            xebk = torch.zeros(len(Xb))\n",
        "            xebk[k_act] = Xb[k_act]\n",
        "            Q_loss.append(yb-self.AttributeNetwork.get_attribute(sb,xebk))\n",
        "            # X loss\n",
        "            sum_Qq = 0\n",
        "            for k in range(self.number_of_attributes):\n",
        "                Xebk = torch.zeros(len(Xb))\n",
        "                Xebk[k] = Xb[k] \n",
        "                # Xe_{b,k}\n",
        "                qek = self.AttributeNetwork.get_attribute(sb1,Xebk)\n",
        "                sum_Qq += qek\n",
        "            X_loss.append(-sum_Qq)\n",
        "\n",
        "        # compute losses as expectation over the experiences batch and update networks\n",
        "\n",
        "        # update thresholds network\n",
        "        # Compute loss\n",
        "        loss_thresholds_network = torch.mean(torch.Tensor(Q_loss))\n",
        "        loss_thresholds_network.requires_grad_()\n",
        "        # Minimize the loss\n",
        "        self.optimizer_ThresholdsNetwork.zero_grad()\n",
        "        loss_thresholds_network.backward()\n",
        "        self.optimizer_ThresholdsNetwork.step()\n",
        "\n",
        "        # update attribute network\n",
        "        # Compute loss\n",
        "        loss_attribute_network = torch.mean(torch.Tensor(X_loss))\n",
        "        loss_attribute_network.requires_grad_()\n",
        "        # Minimize the loss\n",
        "        self.optimizer_AttributeNetwork.zero_grad()\n",
        "        loss_attribute_network.backward()\n",
        "        self.optimizer_AttributeNetwork.step()\n",
        "\n",
        "\n",
        "def env_step(model, node, action):\n",
        "    # update tree\n",
        "    model.set_node_feature(node, feat_index=action[0])\n",
        "    model.set_node_threshold(node, value=action[1])\n",
        "    next_state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "    # calc reward\n",
        "    metrics = model.evaluate(X_val, y_val)\n",
        "    reward = metrics['F1']\n",
        "\n",
        "    done = 0\n",
        "    if model.node_is_leaf(node):\n",
        "        done = 1\n",
        "        \n",
        "    info = 0\n",
        "\n",
        "    return next_state, reward, done, info "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "mCsp4HmwnivF",
        "outputId": "db3c656d-729d-4f68-b978-1916d415d421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using:  cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 365/929 [00:31<00:48, 11.66it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_68151/2267414318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m        \u001b[0;31m# print(f\"node={t}: {model.features[t]}<{model.thresholds[t]} => {action[0]}<{action[1]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mavg_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_68151/3750690128.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_68151/3750690128.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mXeb1k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mXeb1k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXb1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mqek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttributeNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXeb1k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mQq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mmaxQq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_68151/5753983.py\u001b[0m in \u001b[0;36mget_attribute\u001b[0;34m(self, state, threshold_vector)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mindex_selected_attribute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# check argmax output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindex_selected_attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_68151/5753983.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, threshold_vector)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# hyper-parameters\n",
        "HIDDEN_SIZE = 128\n",
        "BUFFER_SIZE = int(1e6)\n",
        "BATCH_SIZE = 16\n",
        "LR_ACTOR = 5e-4 # learning rate\n",
        "LR_CRITIC = 5e-4\n",
        "GAMMA = 0.99    # reward calc\n",
        "nbr_of_conv = 0\n",
        "max_depth = 10\n",
        "n_episodes = 200\n",
        "\n",
        "scores_deque = deque(maxlen=100)\n",
        "writer = SummaryWriter(\"runs/\")\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "model = modDecisionTree(max_depth=max_depth)\n",
        "model.fit(X_train, y_train, df.columns)\n",
        "\n",
        "state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "state_size = len(state)\n",
        "number_of_attributes = X_train.shape[1]\n",
        "threshold_vector_size = X_train.shape[1]\n",
        "\n",
        "agent = Agent(state_size, threshold_vector_size, number_of_attributes, seed, HIDDEN_SIZE)\n",
        "\n",
        "for i_episode in range(1, n_episodes+1):\n",
        "    # state reset => new DT model\n",
        "    model = modDecisionTree(max_depth=max_depth)\n",
        "    model.fit(X_train, y_train, df.columns)\n",
        "    state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "    avg_score = 0\n",
        "    for t in tqdm(range(model.n_nodes)):\n",
        "        if model.node_is_leaf(t):\n",
        "            continue\n",
        "        action = agent.act(state)\n",
        "       # print(f\"node={t}: {model.features[t]}<{model.thresholds[t]} => {action[0]}<{action[1]}\")\n",
        "        next_state, reward, done, info = env_step(model, t, action)\n",
        "        agent.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        avg_score += reward\n",
        "        if done:\n",
        "            break\n",
        "    avg_score /= model.n_nodes\n",
        "\n",
        "    scores_deque.append(avg_score)\n",
        "    writer.add_scalar(\"Reward\", avg_score, i_episode) # for TensorBoard\n",
        "    print('\\rEpisode {} Score: {:.2f}'.format(i_episode, avg_score, end=\"\"))\n",
        "\n",
        "print(f\"final score: {reward}\")\n",
        "t1 = time.time()\n",
        "print(\"training took {} min!\".format((t1-t0)/60))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model.feature_importance())\n",
        "model.plot_tree()\n",
        "model.features_names[15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RLCIskip.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
