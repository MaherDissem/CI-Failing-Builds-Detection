{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP69n7gVXzgJ",
        "outputId": "da2c0399-ab14-4aa6-bfa6-8881f88da091"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 10 15:02:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    74W / 149W |    986MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGOPlW30GFbQ"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybtgjxr_GNBQ",
        "outputId": "e7de51b0-4c46-4915-9eea-9f81c0bb91c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BYNx0HweGFbZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df=pd.DataFrame(\n",
        "    columns = ['build_Failed', 'gh_is_pr', 'git_prev_commit_resolution_status',\n",
        "       'gh_team_size', 'gh_num_commit_comments', 'git_diff_src_churn',\n",
        "       'git_diff_test_churn', 'gh_diff_files_added', 'gh_diff_files_deleted',\n",
        "       'gh_diff_files_modified', 'gh_diff_tests_added',\n",
        "       'gh_diff_tests_deleted', 'gh_diff_src_files', 'gh_diff_doc_files',\n",
        "       'gh_diff_other_files', 'gh_sloc', 'gh_test_lines_per_kloc',\n",
        "       'gh_test_cases_per_kloc', 'gh_asserts_cases_per_kloc', 'tr_build_id',\n",
        "       'gh_build_started_at'],\n",
        "    dtype='object')\n",
        "\n",
        "path = '/mnt/d/PFE/Code/CI-Failing-Builds-Detection/dataset'\n",
        "path = '/content/drive/MyDrive/CI/replicating-ets/DL-CIBuild/dataset'\n",
        "\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        if filename[-4:]==\".csv\":\n",
        "            df = pd.concat([df, pd.read_csv(os.path.join(dirname, filename))])\n",
        "\n",
        "X = df.iloc[:,1:19]\n",
        "y = df.iloc[:,0].astype(int)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val , y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.2, shuffle=True, stratify=y, random_state=42) # keep ratio of classes in split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6lmpxnkGFbk"
      },
      "source": [
        "### Modifiable Decision Tree model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4wzLFR90GFbp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "class modDecisionTree:\n",
        "    \"\"\"\n",
        "    Represents the classification model\n",
        "    based on sklearn implementation with added methods for modifying single nodes\n",
        "    nodes are indexed depth first\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, max_depth=3, random_state=42):\n",
        "        # need to add init of other hyper-param\n",
        "        self.max_depth = max_depth\n",
        "        self.model = DecisionTreeClassifier(max_depth=max_depth, splitter='random', random_state=random_state)\n",
        "    \n",
        "\n",
        "    def fit(self, X_train, y_train, columns_names):\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.tree = self.model.tree_\n",
        "        self.n_nodes = self.tree.node_count       # nbr of nodes\n",
        "        self.features = self.tree.feature         # list of each node's feature\n",
        "        self.thresholds = self.tree.threshold     # list of each node's threshold\n",
        "        self.columns_names = columns_names\n",
        "        self.features_names = [list(self.columns_names)[i] for i in self.features]\n",
        "        self.nodes_type = self.get_nodes_type()  # a node is either a split node or a terminal node/leaf\n",
        "\n",
        "\n",
        "    def evaluate(self, X_val, y_val):\n",
        "        y_pred = self.model.predict(X_val)\n",
        "        metrics = {}\n",
        "        metrics['F1'] = f1_score(y_pred ,y_val)\n",
        "        return metrics\n",
        "\n",
        "\n",
        "    def feature_importance(self):\n",
        "        feat_imp = []\n",
        "        for name, importance in zip(self.features_names , self.model.feature_importances_):\n",
        "            feat_imp.append((name, importance))\n",
        "        feat_imp.sort(key=lambda t:t[1], reverse=True)\n",
        "        return feat_imp\n",
        "\n",
        "\n",
        "    def plot_tree(self):\n",
        "        plt.figure(figsize=(15,10))  # set plot size (denoted in inches)\n",
        "        tree.plot_tree(self.model, fontsize=10, class_names=['pass','fail'])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def get_nodes_type(self):\n",
        "        children_left = self.tree.children_left\n",
        "        children_right = self.tree.children_right\n",
        "        node_depth = np.zeros(shape=self.n_nodes, dtype=np.int64)\n",
        "        is_leaves = np.zeros(shape=self.n_nodes, dtype=bool)\n",
        "        stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
        "        while len(stack) > 0:\n",
        "            # 'pop' ensures each node is only visited once\n",
        "            node_id, depth = stack.pop()\n",
        "            node_depth[node_id] = depth\n",
        "            # If the left and right child of a node is not the same we have a split node\n",
        "            is_split_node = children_left[node_id] != children_right[node_id]\n",
        "            # If a split node, append left and right children and depth to `stack`\n",
        "            # so we can loop through them\n",
        "            if is_split_node:\n",
        "                stack.append((children_left[node_id], depth + 1))\n",
        "                stack.append((children_right[node_id], depth + 1))\n",
        "            else:\n",
        "                is_leaves[node_id] = True\n",
        "        return is_leaves\n",
        "\n",
        "\n",
        "    def node_is_leaf(self, node):\n",
        "        \"\"\"Returns whether a node is a leaf (terminal node) or a split node\"\"\"\n",
        "        return self.nodes_type[node]==1\n",
        "\n",
        "\n",
        "    def set_node_threshold(self, node, value):\n",
        "        if node>=self.tree.node_count:\n",
        "            print(\"Error: selected node id is not in the tree.\")\n",
        "            return\n",
        "        if self.node_is_leaf(node):\n",
        "            print(\"Error: can't change a leaf node's threshold.\")\n",
        "            return\n",
        "        self.thresholds[node] = value \n",
        "\n",
        "\n",
        "    def set_node_feature(self, node, feat_index=None, feat_name=None):\n",
        "        if node>=self.tree.node_count:\n",
        "            print(\"Error: selected node id is not in the tree.\")\n",
        "            return\n",
        "        if self.node_is_leaf(node):\n",
        "            print(\"Error: can't change a terminal node's feature.\")\n",
        "            return\n",
        "        # convert feature name to index if supplied with name\n",
        "        if feat_index==None:\n",
        "            feat_index = self.features_names.index(feat_name)\n",
        "        self.features[node] = feat_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npr9M5hTGFb2"
      },
      "source": [
        "### State Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3kUzGuA_GFb6"
      },
      "outputs": [],
      "source": [
        "def tree_convolution(model, features, thresholds, node=0):\n",
        "    \"\"\"\n",
        "        convolution of each 3 nodes, with overlapping => child of 1 subtree is parent of the next\n",
        "        => after each conv, slit nodes' featuress and thresholdss are updated and terminal nodes are removed\n",
        "        returns new features,thresholds values as lists\n",
        "    \"\"\"\n",
        "    visited = []\n",
        "    queue = []\n",
        "    visited.append(node)\n",
        "    queue.append(node)\n",
        "    new_features = features\n",
        "    new_thresholds = thresholds\n",
        "    #replacing leaf default values -2 by 0 for conv\n",
        "    for node in range(model.n_nodes): \n",
        "        if new_features[node]==-2:\n",
        "            new_features[node]=0\n",
        "        if new_thresholds[node]==-2:\n",
        "            new_thresholds[node]=0\n",
        "    # BFS traversal\n",
        "    while queue:\n",
        "        node = queue.pop(0) \n",
        "        left_node = model.tree.children_left[node]\n",
        "        right_node = model.tree.children_right[node]\n",
        "        #print (node, left_node, right_node, end = \"\\n\")\n",
        "        if left_node not in visited:\n",
        "            visited.append(left_node)\n",
        "            queue.append(left_node)\n",
        "        if right_node not in visited:\n",
        "            visited.append(right_node)\n",
        "            queue.append(right_node)\n",
        "\n",
        "        # define kernel here\n",
        "        if features[left_node]==0 and features[right_node]==0: # both child nodes are leaves\n",
        "            new_node_features = 0\n",
        "            new_node_thresholds = 0\n",
        "        elif features[left_node]==0: # left node is leaf\n",
        "            new_node_features = (features[node]+features[right_node])/2\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[right_node])/2\n",
        "        elif features[right_node]==0: # right node is leaf\n",
        "            new_node_features = (features[node]+features[left_node])/2\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[left_node])/2\n",
        "        else:\n",
        "            new_node_features = (features[node]+features[left_node]+features[right_node])/3\n",
        "            new_node_thresholds = (thresholds[node]+thresholds[left_node]+thresholds[right_node])/3\n",
        "        # save new values\n",
        "        new_features[node] = new_node_features # will auto convert to int \n",
        "        new_thresholds[node] = new_node_thresholds\n",
        "\n",
        "    return new_features, new_thresholds\n",
        "\n",
        "\n",
        "def flatten(features, thresholds):\n",
        "    return torch.cat((torch.FloatTensor(features), torch.FloatTensor(thresholds))).to(device)\n",
        "\n",
        "\n",
        "def generate_state(model, features, thresholds, nbr_of_conv):\n",
        "    features, thresholds = features.copy(), thresholds.copy()\n",
        "    for _ in range(nbr_of_conv):\n",
        "        new_features, new_thresholds = tree_convolution(model, features, thresholds) # model must be fitted => add condition?\n",
        "        features, thresholds = new_features, new_thresholds\n",
        "    return flatten(features, thresholds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHxiDxA1GFb_"
      },
      "source": [
        "### Reinforcement Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JvPXR-dglv1c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from collections import namedtuple, deque\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UtpIy8-Wlyj5"
      },
      "outputs": [],
      "source": [
        "class ThresholdsNetwork(nn.Module):\n",
        "    \"\"\"Network that will predict the new thresholds vector given a state.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, seed, hidden_size=32):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            threshold_vector_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "            hidden_size (int): Number of nodes in hidden layers\n",
        "        \"\"\"\n",
        "        super(ThresholdsNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)     \n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        #self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, threshold_vector_size)\n",
        "\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state), inplace=True)\n",
        "        #x = F.relu(self.fc2(x), inplace=True)\n",
        "        out = self.fc3(x)\n",
        "        return out\n",
        "    \n",
        "\n",
        "    def get_thresholds_vector(self, state):\n",
        "        threshold_vector = self.forward(state).to(device)\n",
        "        return threshold_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oBuGtzpomnrn"
      },
      "outputs": [],
      "source": [
        "class AttributeNetwork(nn.Module):\n",
        "    \"\"\"Network that will select a new attribute for a tree node given the environment state and thresholds vector\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, number_of_attributes, seed, hidden_size=32):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            threshold_vector_size (int): Dimension of each threshold vector\n",
        "            seed (int): Random seed\n",
        "            hidden_size (int): Number of nodes in the network layers\n",
        "\n",
        "        \"\"\"\n",
        "        super(AttributeNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size+threshold_vector_size, hidden_size)\n",
        "        #self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, number_of_attributes)\n",
        "\n",
        "\n",
        "    def forward(self, state, threshold_vector):\n",
        "        \"\"\"Build a critic (value) network that maps (state, threshold_vector) pairs -> Q-values.\"\"\"\n",
        "        x = torch.cat((state, threshold_vector), dim=-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "    def get_attributes_vector(self, state, threshold_vector, Xe_vect=False):\n",
        "        if Xe_vect:\n",
        "            # the input threshold vector is Xe instead of X; for the calc of target yb\n",
        "            attributes_vector = self.forward(state, threshold_vector)\n",
        "\n",
        "        else:\n",
        "            # decompose (st,X) input into (st,Xe_k) for each k \n",
        "            attributes_vector = torch.zeros(len(threshold_vector)).to(device)\n",
        "            X = threshold_vector\n",
        "            for k in range(len(X)):\n",
        "                Xe = torch.zeros(len(X)).to(device)    \n",
        "                Xe[k] = X[k]\n",
        "                q_vect = self.forward(state,Xe)\n",
        "                attributes_vector[k] = q_vect[k]\n",
        "        return attributes_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qvkm_2I6GFcO"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, buffer_size, batch_size, seed):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "        \"\"\"\n",
        "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "        states = torch.vstack([e.state for e in experiences if e is not None]).float().to(device)\n",
        "        actions = torch.vstack([torch.tensor(e.action) for e in experiences if e is not None]).float().to(device)\n",
        "        rewards = torch.vstack([torch.tensor(e.reward) for e in experiences if e is not None]).float().to(device)\n",
        "        next_states = torch.vstack([e.next_state for e in experiences if e is not None]).float().to(device)\n",
        "        dones = torch.vstack([torch.tensor(e.done) for e in experiences if e is not None]).float().to(device)\n",
        "        return zip(states, actions, rewards, next_states, dones)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6TAr3AwlnXEW"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self, state_size, threshold_vector_size, number_of_attributes, random_seed, hidden_size):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            threshold_vector_size (int): dimension of each threshold vector\n",
        "            random_seed (int): random seed\n",
        "            add rest\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.threshold_vector_size = threshold_vector_size\n",
        "        self.number_of_attributes = number_of_attributes\n",
        "        self.seed = random.seed(random_seed)\n",
        "        print(\"Using: \", device)\n",
        "\n",
        "        # actor Network \n",
        "        self.ThresholdsNetwork = ThresholdsNetwork(state_size, threshold_vector_size, random_seed, hidden_size).to(device)\n",
        "        self.optimizer_ThresholdsNetwork = optim.Adam(self.ThresholdsNetwork.parameters(), lr=LR_ACTOR)     \n",
        "        \n",
        "        # critic Network  \n",
        "        self.AttributeNetwork = AttributeNetwork(state_size, threshold_vector_size, number_of_attributes, random_seed, hidden_size).to(device)\n",
        "        self.optimizer_AttributeNetwork = optim.Adam(self.AttributeNetwork.parameters(), lr=LR_CRITIC, weight_decay=0)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
        "        \n",
        "\n",
        "    def act(self, state, eps=0.2):\n",
        "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
        "        # greedy epsilon with param eps\n",
        "        thresholds_vector = self.ThresholdsNetwork.get_thresholds_vector(state)\n",
        "\n",
        "        p = np.random.random() \n",
        "        if p<eps:\n",
        "            index_selected_attribute = random.choice(range(self.number_of_attributes))\n",
        "        else:\n",
        "            attributes_vector = self.AttributeNetwork.get_attributes_vector(state, thresholds_vector)\n",
        "            index_selected_attribute = torch.argmax(attributes_vector)\n",
        "        action = (index_selected_attribute, thresholds_vector.squeeze(0)[index_selected_attribute])\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
        "        # Save experience / reward\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # if enough samples are available in memory\n",
        "        # sample a minibatch and learn/update networks\n",
        "        if len(self.memory) > BATCH_SIZE:\n",
        "            experiences = self.memory.sample()\n",
        "            self.learn(experiences, GAMMA)\n",
        "\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Updates the two neural networks using given batch of experience tuples.\n",
        "        Critic_loss = \n",
        "        Actor_loss = \n",
        "        where:\n",
        "            actor_target(state) -> action\n",
        "            critic_target(state, action) -> Q-value\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        Q_loss, X_loss = [], []\n",
        "        for experience in experiences: # for b in B\n",
        "            state, action, reward, next_state, done = experience\n",
        "            sb = state\n",
        "            k_act = int(action[0].item())\n",
        "            rb = reward\n",
        "            sb1 = next_state # S_{b+1}\n",
        "            Xb1 = self.ThresholdsNetwork.get_thresholds_vector(sb1) # X_{b+1}\n",
        "            Xb = self.ThresholdsNetwork.get_thresholds_vector(sb) # X_{b}\n",
        "            # yb calc\n",
        "            # get max_k(Qq)\n",
        "            Qq = []\n",
        "            for k in range(self.number_of_attributes):\n",
        "                # get Xe_{b+1}\n",
        "                Xeb1k = torch.zeros(len(Xb1)).to(device)\n",
        "                Xeb1k[k] = Xb1[k]\n",
        "                qek = torch.max(self.AttributeNetwork.get_attributes_vector(sb1, Xeb1k, Xe_vect=True))\n",
        "                Qq.append(qek)\n",
        "            maxQq = torch.max(torch.Tensor(Qq))\n",
        "\n",
        "            if done: # terminal node\n",
        "                yb = rb\n",
        "            else:\n",
        "                yb = rb + gamma * maxQq\n",
        "\n",
        "            # compute losses for single transitions\n",
        "\n",
        "            # Q loss\n",
        "            xebk = torch.zeros(len(Xb)).to(device)\n",
        "            xebk[k_act] = Xb[k_act]\n",
        "            Q_loss.append(yb-self.AttributeNetwork.get_attributes_vector(sb, xebk, Xe_vect=True)[k_act])\n",
        "            \n",
        "            # X loss\n",
        "            sum_Qq = 0\n",
        "            for k in range(self.number_of_attributes):\n",
        "                Xebk = torch.zeros(len(Xb)).to(device)\n",
        "                Xebk[k] = Xb[k] \n",
        "                # Xe_{b,k}\n",
        "                qek = self.AttributeNetwork.get_attributes_vector(sb1, Xebk, Xe_vect=True)\n",
        "                sum_Qq += qek[k]\n",
        "            X_loss.append(-sum_Qq)\n",
        "\n",
        "        # compute losses as expectation over the experiences batch and update networks\n",
        "\n",
        "        # update thresholds network\n",
        "        # Compute loss\n",
        "        loss_thresholds_network = torch.mean(torch.Tensor(Q_loss))\n",
        "        loss_thresholds_network.requires_grad_()\n",
        "        # Minimize the loss\n",
        "        self.optimizer_ThresholdsNetwork.zero_grad()\n",
        "        loss_thresholds_network.backward()\n",
        "        self.optimizer_ThresholdsNetwork.step()\n",
        "\n",
        "        # update attribute network\n",
        "        # Compute loss\n",
        "        loss_attribute_network = torch.mean(torch.Tensor(X_loss))\n",
        "        loss_attribute_network.requires_grad_()\n",
        "        # Minimize the loss\n",
        "        self.optimizer_AttributeNetwork.zero_grad()\n",
        "        loss_attribute_network.backward()\n",
        "        self.optimizer_AttributeNetwork.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev_metric = 0\n",
        "\n",
        "def env_step(model, node, action):\n",
        "    # update tree\n",
        "    model.set_node_feature(node, feat_index=action[0])\n",
        "    model.set_node_threshold(node, value=action[1])\n",
        "    next_state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "    # calc reward\n",
        "    global prev_metric\n",
        "    metrics = model.evaluate(X_val, y_val)\n",
        "    current_metric = metrics['F1']\n",
        "    reward = current_metric-prev_metric \n",
        "    prev_metric = current_metric\n",
        "    done = 0\n",
        "    if model.node_is_leaf(node):\n",
        "        done = 1\n",
        "        \n",
        "    info = 0\n",
        "\n",
        "    return next_state, reward, done, info "
      ],
      "metadata": {
        "id": "E0JMe-AkYD54"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCsp4HmwnivF",
        "outputId": "f148b513-e9fe-4008-ac18-ea1c261b89eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree depth=15, state size=12046, number of attribute=18\n",
            "Using:  cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|‚ñè         | 147/6023 [00:20<1:07:03,  1.46it/s]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# hyper-parameters\n",
        "HIDDEN_SIZE = 128\n",
        "BUFFER_SIZE = int(1e6)\n",
        "BATCH_SIZE = 64\n",
        "LR_ACTOR = 5e-4 # learning rate\n",
        "LR_CRITIC = 5e-4\n",
        "GAMMA = 0.99    # reward calc\n",
        "nbr_of_conv = 0\n",
        "max_depth = 15\n",
        "n_episodes = 200\n",
        "\n",
        "scores_deque = deque(maxlen=100)\n",
        "writer = SummaryWriter(\"runs/\")\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "model = modDecisionTree(max_depth=max_depth)\n",
        "model.fit(X_train, y_train, df.columns)\n",
        "\n",
        "state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "state_size = len(state)\n",
        "number_of_attributes = X_train.shape[1]\n",
        "threshold_vector_size = X_train.shape[1]\n",
        "print(f'tree depth={max_depth}, state size={state_size}, number of attribute={number_of_attributes}')\n",
        "\n",
        "agent = Agent(state_size, threshold_vector_size, number_of_attributes, seed, HIDDEN_SIZE)\n",
        "\n",
        "for i_episode in range(1, n_episodes+1):\n",
        "    # state reset => new DT model\n",
        "    model = modDecisionTree(max_depth=max_depth)\n",
        "    model.fit(X_train, y_train, df.columns)\n",
        "    state = generate_state(model, model.features, model.thresholds, nbr_of_conv)\n",
        "    avg_score = 0\n",
        "    for t in tqdm(range(model.n_nodes)):\n",
        "        if model.node_is_leaf(t):\n",
        "            continue\n",
        "        action = agent.act(state)\n",
        "       # print(f\"node={t}: {model.features[t]}<{model.thresholds[t]} => {action[0]}<{action[1]}\")\n",
        "        next_state, reward, done, info = env_step(model, t, action)\n",
        "        agent.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        avg_score += reward\n",
        "        if done:\n",
        "            break\n",
        "    avg_score /= model.n_nodes\n",
        "\n",
        "    scores_deque.append(avg_score)\n",
        "    writer.add_scalar(\"Reward\", avg_score, i_episode) # for TensorBoard\n",
        "    print('\\rEpisode {} Score: {:.2f}'.format(i_episode, avg_score, end=\"\"))\n",
        "\n",
        "print(f\"final score: {reward}\")\n",
        "t1 = time.time()\n",
        "print(\"training took {} min!\".format((t1-t0)/60))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3MwZwNFGFcV"
      },
      "outputs": [],
      "source": [
        "print(model.feature_importance())\n",
        "model.plot_tree()\n",
        "model.features_names[15]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TNtewLKXe_ly"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RLCIskip.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}