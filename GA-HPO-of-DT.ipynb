{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EiFfZijfRtht"},"outputs":[],"source":["\"\"\"Class that represents the solution to be evolved.\"\"\"\n","import random\n","class Solution():\n","    def __init__(self, all_possible_params):\n","        self.entry = {}\n","        self.score = 0.\n","        self.all_possible_params = all_possible_params\n","        self.params = {}  #  represents model parameters to be picked by creat_random method\n","        self.model = None\n","        \n","    \"\"\"Create the model random params.\"\"\"\n","    def create_random(self):\n","        for key in self.all_possible_params:\n","            self.params[key] = random.choice(self.all_possible_params[key])\n","\n","    def set_params(self, params):\n","        self.params = params\n","      \n","    \"\"\"\n","        Train the model and record the score.\n","    \"\"\"\n","    def train_model(self, fn_train,params_fn):\n","        \n","        if self.score == 0.:\n","                res = fn_train(self.params,params_fn)\n","                self.score =  res[\"entry\"][\"F1\"] #1-float(res[\"validation_loss\"])\n","                self.model = res[\"model\"]\n","                self.entry = res['entry']\n","            \n","    \"\"\"Print out a network.\"\"\"\n","    def print_solution(self):\n","        print(\"for params \", self.params , \"the score in the train = \",self.score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGRpm6vORthy"},"outputs":[],"source":["\"\"\"\n","Class that holds a genetic algorithm for evolving a population of params.\n","\"\"\"\n","from functools import reduce\n","from operator import add\n","import random\n","\"\"\"Class that implements genetic algorithm for Hyper-parameter tuning\"\"\"\n","class Optimizer():\n","    \n","    def __init__(self, GA_params, all_possible_params):\n","        \"\"\"Create an optimizer.\"\"\"\n","        self.random_select = GA_params[\"random_select\"]\n","        self.mutate_chance = GA_params[\"mutate_chance\"]\n","        self.retain = GA_params[\"retain\"]\n","        self.all_possible_params = all_possible_params\n","    \n","    def create_population(self, count):\n","        \"\"\"Create a population of random solutions.\"\"\"\n","        pop = []\n","        for _ in range(0, count):\n","            # Create a random solution.\n","            solution = Solution(self.all_possible_params)\n","            solution.create_random()\n","            # Add the solution to our population.\n","            pop.append(solution)\n","        return pop\n","\n","    @staticmethod\n","    def fitness(solution):\n","        \"\"\"Return the score, which is our fitness function.\"\"\"\n","        return solution.score\n","\n","    def grade(self, pop):\n","        \"\"\"Find average fitness for a population. \"\"\"\n","        summed = reduce(add, (self.fitness(solution) for solution in pop))\n","        return summed / float((len(pop)))\n","\n","    def crossover(self, mother, father):\n","        \"\"\"Make two children as parts of their parents.\n","        Args:\n","            mother (dict): parameters\n","            father (dict): parameters\n","        Returns:\n","            (list): combined params\n","        \"\"\"\n","        children = []\n","        for _ in range(2):\n","            child = {}\n","            # Loop through the parameters and pick params for the kid.\n","            for param in self.all_possible_params:\n","                child[param] = random.choice([mother.params[param], father.params[param]] )\n","\n","            solution = Solution(self.all_possible_params)\n","            solution.set_params(child)\n","            # Randomly mutate some of the children.\n","            if self.mutate_chance > random.random():\n","                solution = self.mutate(solution)\n","            children.append(solution)\n","        return children\n","    \n","    \n","    def mutate(self, solution):\n","        \"\"\"Randomly mutate one part of the solution.\"\"\"\n","        # Choose a random key.\n","        mutation = random.choice(list(self.all_possible_params.keys()))\n","        # Mutate one of the params.\n","        solution.params[mutation] = random.choice(self.all_possible_params[mutation])\n","        return solution\n","    \n","    \"\"\"Evolve a population of solutions.\"\"\"\n","    def evolve(self, pop):\n","        #Get scores for each solution.\n","        graded = [(self.fitness(solution), solution) for solution in pop]\n","        #\"Sort on the scores.\n","        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n","        #Get the number we want to keep for the next gen.\n","        retain_length = int(len(graded)*self.retain)\n","        # define what we want to keep.\n","        parents = graded[:retain_length]\n","        # For those we aren't keeping, randomly keep some anyway.\n","        for individual in graded[retain_length:]:\n","            if self.random_select > random.random():\n","                parents.append(individual)\n","        # Now find out how many spots we have left to fill.\n","        parents_length = len(parents)\n","        desired_length = len(pop) - parents_length\n","        \n","        # Add children, which are bred from two remaining solutions.\n","        if parents_length > 1 and desired_length> 0:\n","            children = []\n","            while len(children) < desired_length:\n","                if parents_length==2:\n","                    male_index = 1\n","                    female_index = 0\n","                else:\n","                    male_index = random.randint(0, parents_length-1)\n","                    female_index = random.randint(0, parents_length-1)\n","                \n","                # Assuming they aren't the same solutions...\n","                if male_index != female_index:\n","                    print(\"Get a random mom and dad.\")\n","                    male = parents[male_index]\n","                    female = parents[female_index]\n","                    # crossover them.\n","                    babies = self.crossover(male, female)\n","                    # Add the children one at a time.\n","                    for baby in babies:\n","                        # Don't grow larger than desired length.\n","                        if len(children) < desired_length:\n","                            children.append(baby)\n","            parents.extend(children)\n","        return parents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt6J4nU1Rth3"},"outputs":[],"source":["from tqdm import tqdm\n","import threading\n","def train_sol_thread(solution,fn_train,params_fn,i):\n","    solution.train_model(fn_train,params_fn)\n","    print(\"solution \", i,\" trained\")\n","    \n","def train_population(pop, fn_train,params_fn):\n","    pbar = tqdm(total=len(pop))\n","    threads = list()\n","    i=1\n","    for solution in pop:\n","        x = threading.Thread(target=train_sol_thread, args=(solution,fn_train,params_fn,i))\n","        i=i+1\n","        threads.append(x)\n","        x.start()\n","        pbar.update(1)\n","        \n","    for index, thread in enumerate(threads):\n","        thread.join()\n","    pbar.close()\n","\n","\n","def get_average_score(pop):\n","    \"\"\"Get the average score for a group of solutions.\"\"\"\n","    total_scores = 0\n","    for solution in pop:\n","        total_scores += solution.score\n","    return total_scores / len(pop)\n","\n","\"\"\"Generate the optimal params with the genetic algorithm.\"\"\"\n","\"\"\" Args:\n","        GA_params: Params for GA\n","        all_possible_params (dict): Parameter choices for the model\n","        train_set : training dataset\n","        fn_train : a function used to compute the prediction accuracy\n","\"\"\"\n","def generate(all_possible_params, fn_train , params_fn):\n","   \n","    GA_params = {\n","            \"population_size\": nbr_sol,\n","            \"max_generations\": nbr_gen,\n","            \"retain\": 0.7,\n","            \"random_select\":0.1,\n","            \"mutate_chance\":0.1\n","            }\n","    \n","    print(\"params of GA\" , GA_params)\n","    optimizer = Optimizer(GA_params ,all_possible_params)\n","    pop = optimizer.create_population(GA_params['population_size'])\n","    # Evolve the generation.\n","    for i in range(GA_params['max_generations']):\n","        print(\"*********************************** REP(GA) \",(i+1))\n","        # Train and get accuracy for solutions.\n","        train_population(pop,fn_train,params_fn)\n","        # Get the average accuracy for this generation.\n","        average_accuracy = get_average_score(pop)\n","        # Print out the average accuracy each generation.\n","        print(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n","        # Evolve, except on the last iteration.\n","        if i != (GA_params['max_generations']):\n","            print(\"Generation evolving..\")\n","            evolved = optimizer.evolve(pop)\n","            if(len(evolved)!=0):\n","                pop=evolved\n","        else:\n","            pop = sorted(pop, key=lambda x: x.score, reverse=True)\n","    # Print out the top 2 solutions.\n","    size = len(pop)\n","    if size < 3:\n","        print_pop(pop[:size])\n","    else:\n","        print_pop(pop[:3])\n","    return pop[0].params ,pop[0].model,pop[0].entry\n","\n","def print_pop(pop):\n","    for solution in pop:\n","        solution.print_solution()    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2xzMaT1Rth7"},"outputs":[],"source":["\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import warnings # `do not disturbe` mode\n","warnings.filterwarnings('ignore')\n","sc = StandardScaler()\n","from numpy import arange\n","from numpy import argmax\n","\n","nbr_rep = 6\n","nbr_gen = 2\n","nbr_sol = 2\n","max_eval = nbr_gen*nbr_sol\n","\n","with_smote = False \n","hybrid_option = False # means smote and threshold moving\n","\n","if hybrid_option:\n","    with_smote =True\n","\n","\n","def getDataset(file_name):\n","    dataset = pd.read_csv(\"dataset/\"+file_name, \n","                          parse_dates=['gh_build_started_at'], \n","                          index_col=\"gh_build_started_at\")\n","    dataset.sort_values(by=['gh_build_started_at'], inplace=True)\n","    return dataset\n","    \n","# apply threshold to positive probabilities to create labels\n","def to_labels(pos_probs, threshold):\n","    return (pos_probs >= threshold).astype('int')\n","\n","def getBestThreshold(probs, y_train):\n","    # keep probabilities for the positive outcome only\n","    #probs = predicted_builds[:, 1]\n","    thresholds = arange(0, 1, 0.001)\n","    # evaluate each threshold\n","    scores = [roc_auc_score(y_train, to_labels(probs, t)) for t in thresholds]\n","    # get best threshold\n","    ix = argmax(scores)\n","    #print('\\nThreshold=%.2f, AUC=%.2f' % (thresholds[ix], scores[ix]))\n","    return  thresholds[ix]\n","\n","\n","def failureInfo(dataset):\n","    condition =  dataset['build_Failed'] > 0\n","    rate = (dataset[condition].shape[0]) /dataset.shape[0]\n","    size=dataset.shape[0]\n","    return rate,size\n","\n","def getEntry(y, predicted_builds):\n","    entry = {}\n","    entry[\"AUC\"] =  roc_auc_score(y, predicted_builds)\n","    entry[\"accuracy\"] =  accuracy_score(y, predicted_builds)\n","    entry[\"F1\"] =  f1_score(y,predicted_builds)\n","    return entry\n","\n","def predict_model(classifier,X,y):\n","    predicted_builds = classifier.predict(X)\n","    \n","    if with_smote and not hybrid_option:\n","        decision_threshold = 0.5\n","    else:\n","        decision_threshold = getBestThreshold(predicted_builds, y)\n","        \n","    predicted_builds = (predicted_builds >= decision_threshold)\n","    return getEntry(y, predicted_builds)\n","\n","def isInt(n):\n","    try:\n","        n=int(n)\n","        return True\n","    except:\n","        return False\n","\n","def frange(start, stop=None, step=None):\n","\n","    if stop == None:\n","        stop = start + 0.0\n","        start = 0.0\n","\n","    if step == None:\n","        step = 1.0\n","\n","    while True:\n","        if step > 0 and start >= stop:\n","            break\n","        elif step < 0 and start <= stop:\n","            break\n","        yield (\"%g\" % start) # return float number\n","        start = start + step\n","        \n","def frange_int(start, stop=None, step=None):\n","\n","    if stop == None:\n","        stop = start \n","        start = 0\n","\n","    if step == None:\n","        step = 1\n","\n","    while True:\n","        if step > 0 and start >= stop:\n","            break\n","        elif step < 0 and start <= stop:\n","            break\n","        yield (start) # return int number\n","        start = start + step\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87CqIqT_Rth-"},"outputs":[],"source":["from hyperopt import hp,Trials,STATUS_OK ,fmin,tpe,rand\n","from keras.models import Sequential\n","from keras.layers import Dense,LSTM,Dropout\n","from keras.callbacks import EarlyStopping\n","import optunity\n","import optunity.metrics\n","import numpy as np\n","import pandas as pd\n","from imblearn.over_sampling import SMOTE\n","import ConfigSpace as CS\n","from hpbandster.core.worker import Worker\n","from hpbandster.optimizers import BOHB as BOHB\n","from timeit import default_timer as timer\n","\n","with_smote=0\n","\n","def train_preprocess(dataset_train):\n","    \n","    X_train = dataset_train.iloc[:,1:19]\n","    y_train = dataset_train.iloc[:,0]\n","\n","    if with_smote:\n","        X= training_set\n","        y= dataset_train.iloc[:,0].values\n","        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n","        training_set = X\n","\n","    return X_train, y_train\n","\n","def test_preprocess(dataset_test):\n","\n","    X_test = dataset_test.iloc[:,1:19]\n","    y_test = dataset_test.iloc[:,0]\n","\n","    X_test, y_test = np.array(X_test), np.array(y_test).astype(int)\n","\n","    return X_test,y_test\n","\n","def get_threshold_list(dataset):\n","    cdt =  dataset['build_Failed'] > 0\n","    failure_rate = (dataset[cdt].shape[0] /dataset.shape[0])\n","    return list(frange(0.01,max(1,failure_rate), 0.1))\n","\n","class LSTMWorker(Worker):\n","    def __init__(self,  train_set, **kwargs):\n","        super().__init__(**kwargs)\n","        self.train_set= train_set\n","\n","    def compute(self, config, *args, **kwargs):\n","        res = construct_model(config,self.train_set)\n","        return({\n","                    'loss': float(res[\"validation_auc\"]),  # this is the a mandatory field to run hyperband,   \n","                    #remember: HpBandSter always minimizes!\n","                    'info': res[\"entry\"] # can be used for any user-defined information - also mandatory\n","                })\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","\n","def construct_model (model_params,train_set):\n","\n","    X, y = train_preprocess(train_set)\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n","\n","    classifier = DecisionTreeClassifier(\n","        ccp_alpha = model_params[\"ccp_alpha\"],\n","    #    class_weigh = model_params[\"class_weigh\"],\n","    #    criterion = model_params[\"criterion\"],\n","        max_depth = model_params[\"max_depth\"],\n","        max_features = model_params[\"max_features\"],\n","    #    max_leaf_nodes = model_params[\"max_leaf_nodes\"],\n","    #    min_impurity_decrease = model_params[\"min_impurity_decrease\"],\n","    #    min_samples_leaf = model_params[\"min_samples_leaf\"],\n","    #    min_samples_split = model_params[\"min_samples_split\"],\n","    #    min_weight_fraction_leaf = model_params[\"min_weight_fraction_leaf\"],\n","    #    splitter = model_params[\"splitter\"]\n","    )\n","\n","    result =  classifier.fit(X_train, y_train)\n","\n","    y_pred = result.predict(X_val)\n","\n","    # Get the lowest validation loss of the training epochs\n","    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_pred)\n","    roc_auc = auc(false_positive_rate, true_positive_rate)\n","\n","    # Get prediction probs\n","    entry = predict_model(classifier,X_train,y_train)\n","    entry['validation_auc']=roc_auc\n","    return      {\n","                'validation_auc'  : roc_auc, #required by GA\n","                'model'   : classifier, #required by GA\n","                \"entry\"  : entry ,#required by GA\n","                }\n","global data\n","global global_params\n","global global_model\n","global global_entry\n","\n","\n","def evaluate_tuner(tuner_option, train_set):\n","    global data\n","    data = train_set\n","    #########################################\n","    ccp_alpha = [0.0]\n","    # class_weigh =\n","    # criterion = \n","    max_depth = [30,50,70]\n","    max_features = [5,10,15]\n","    # max_leaf_nodes = \n","    # min_impurity_decrease =\n","    # min_samples_leaf = \n","    # min_samples_split = \n","    # min_weight_fraction_leaf = \n","    ##########################################################\n","    start = timer()\n","    \n","    param_choices = {\n","        'max_depth':   max_depth,\n","        'ccp_alpha':  ccp_alpha,\n","        'max_features':  max_features,\n","\n","    }\n","    best_params ,best_model , entry_train = generate(param_choices, construct_model, data)\n","\n","\n","    end = timer()\n","    period = (end - start)\n","    entry_train[\"time\"] = period\n","    entry_train[\"params\"] = best_params\n","    entry_train[\"model\"]  = best_model\n","    return entry_train\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsbIXLmYRtiA"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","global columns_res,columns_comp\n","columns_res = [\"proj\"]+[\"algo\"]+[\"iter\"]+[\"AUC\"]+[\"accuracy\"]+[\"F1\"]+[\"exp\"]\n","\n","tuner = \"ga\"\n","results = pd.DataFrame(columns =  columns_res)\n","results_train = pd.DataFrame(columns =  columns_res)\n","bellwether=\"jruby.csv\"\n","trainset = getDataset(bellwether)\n","for iteration in range (1,nbr_rep):\n","    entry_train  = evaluate_tuner(tuner,trainset)\n","    best_params = entry_train[\"params\"]\n","    best_model = entry_train[\"model\"]\n","    print(iteration,\"*************************************** TRAIN\",bellwether)\n","    entry_train[\"iter\"] = iteration\n","    entry_train[\"proj\"] = bellwether\n","    entry_train[\"algo\"] = \"DT\"\n","    entry_train[\"params\"] = best_params\n","    results_train = results_train.append(entry_train,ignore_index=True)\n","    print(\"entry_train\",entry_train)\n","    for file_name in os.listdir(\"dataset\"):\n","        if file_name!=bellwether:\n","            #print(file_name)\n","            testset = getDataset(file_name)\n","            X,y = test_preprocess(testset)\n","            entry= predict_model(best_model,X,y)\n","            entry[\"iter\"] = iteration\n","            entry[\"proj\"] = file_name\n","            entry[\"exp\"] =  1\n","            entry[\"algo\"] = \"DT\"\n","            results = results.append(entry,ignore_index=True)\n","results.to_excel(\"corss_proj_paramf_\"+str(hybrid_option)+str(with_smote)+\"_result_crossProj_\"+tuner+\"_DT.xlsx\")\n","results_train.to_excel(\"cross_paramf\"+str(hybrid_option)+str(with_smote)+\"_train_crossProj_\"+tuner+\"_DT.xlsx\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVvCj6j5RtiC"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_I3s3E0RtiD"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"iJsOJD-8RtiH"},"source":["displaying a desision tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mwe7KjERtiM"},"outputs":[],"source":["from sklearn.tree import _tree\n","\n","def get_rules(tree, feature_names, class_names):\n","    tree_ = tree.tree_\n","    feature_name = [\n","        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n","        for i in tree_.feature\n","    ]\n","\n","    paths = []\n","    path = []\n","    \n","    def recurse(node, path, paths):\n","        \n","        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n","            name = feature_name[node]\n","            threshold = tree_.threshold[node]\n","            p1, p2 = list(path), list(path)\n","            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n","            recurse(tree_.children_left[node], p1, paths)\n","            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n","            recurse(tree_.children_right[node], p2, paths)\n","        else:\n","            path += [(tree_.value[node], tree_.n_node_samples[node])]\n","            paths += [path]\n","            \n","    recurse(0, path, paths)\n","\n","    # sort by samples count\n","    samples_count = [p[-1][1] for p in paths]\n","    ii = list(np.argsort(samples_count))\n","    paths = [paths[i] for i in reversed(ii)]\n","    \n","    rules = []\n","    for path in paths:\n","        rule = \"if \"\n","        \n","        for p in path[:-1]:\n","            if rule != \"if \":\n","                rule += \" and \"\n","            rule += str(p)\n","        rule += \" then \"\n","        if class_names is None:\n","            rule += \"response: \"+str(np.round(path[-1][0][0][0],3))\n","        else:\n","            classes = path[-1][0][0]\n","            l = np.argmax(classes)\n","            rule += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n","        rule += f\" | based on {path[-1][1]:,} samples\\n\"\n","        rules += [rule]\n","        \n","    return rules\n","\n","rules = get_rules(dt, list(df.columns), ['pass','fail'])\n","for r in rules:\n","    print(r)"]}],"metadata":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4,"colab":{"name":"GA-HPO-of-DT.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}