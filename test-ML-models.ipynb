{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipCI dataset\n",
    "columns = ['ci_skipped', 'ns', 'nd', 'nf', 'entropy', 'la', 'ld', 'lt', 'ndev',\n",
    "       'age', 'nuc', 'exp', 'rexp', 'sexp', 'TFC', 'is_doc', 'is_build',\n",
    "       'is_meta', 'is_media', 'is_src', 'is_merge', 'FRM', 'COM', 'CFT',\n",
    "       'classif', 'prev_com_res', 'proj_recent_skip', 'comm_recent_skip',\n",
    "       'same_committer', 'is_fix', 'day_week', 'CM', 'commit_hash']\n",
    "\n",
    "path = '/content/drive/MyDrive/CI/SkipCI-dataset'\n",
    "path = '/mnt/d/PFE/Papers Presentations/1SkipCI/SkipCI/dataset/'\n",
    "\n",
    "# projects list: \n",
    "# candybar-library.csv  GI.csv               mtsar.csv     ransack.csv     SemanticMediaWiki.csv\n",
    "# contextlogger.csv     grammarviz2_src.csv  parallec.csv  SAX.csv         solr-iso639-filter.csv\n",
    "# future.csv            groupdate.csv        pghero.csv    searchkick.csv  steve.csv\n",
    "\n",
    "valid_proj = 'SemanticMediaWiki.csv'\n",
    "cols_to_keep = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_eval(valid_proj):\n",
    "    df = pd.read_csv(os.path.join(path, valid_proj))\n",
    "    X = df.iloc[:,1:cols_to_keep]\n",
    "    y = df.iloc[:,0].astype(int)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val , y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.2, shuffle=True, stratify=y, random_state=42) # keep ratio of classes in split\n",
    "\n",
    "    eval_meth = f'within_proj_{valid_proj}'[:-4]\n",
    "\n",
    "    train(X_train, X_val, y_train, y_val, df, eval_meth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_val, y_train, y_val, df, eval_meth):\n",
    "    print(m)\n",
    "    if m=='rf':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    if m=='dt':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Classification metrics calculations\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    confusion = confusion_matrix(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    print(report)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('\\nF1=%.3f' % (f1))\n",
    "    print('\\nAUC=%.3f' % (auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.17      0.21        18\n",
      "           1       0.69      0.82      0.75        40\n",
      "\n",
      "    accuracy                           0.62        58\n",
      "   macro avg       0.49      0.50      0.48        58\n",
      "weighted avg       0.57      0.62      0.58        58\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 3 15]\n",
      " [ 7 33]]\n",
      "\n",
      "F1=0.750\n",
      "\n",
      "AUC=0.496\n"
     ]
    }
   ],
   "source": [
    "m='dt'\n",
    "within_eval(\"candybar-library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for valid_proj in ['candybar-library.csv','GI.csv', 'mtsar.csv', 'ransack.csv', 'SemanticMediaWiki.csv', 'contextlogger.csv', 'grammarviz2_src.csv', 'parallec.csv', 'SAX.csv', 'solr-iso639-filter.csv', 'future.csv', 'groupdate.csv', 'pghero.csv', 'searchkick.csv', 'steve.csv']:\n",
    "    within_eval(valid_proj)\n",
    "    #cross_eval(valid_proj)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
